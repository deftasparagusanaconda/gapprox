the Optimizer stateful function (implementationally a class) should not collapse the rewards into a single value, as this undermines the pareto points, and prevents us from exposing a front of them. so when comparing one approximation with another, only consider approximations that push the pareto front, not by collapsing the reward values into one value and then comparing linearly on the real number line
